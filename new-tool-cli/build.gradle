plugins {
  id 'net.saliman.properties' version '1.5.2'
  id "application"
  id "jacoco"
  id "org.sonarqube" version "4.4.1.3373"
  id 'com.github.johnrengelman.shadow' version '8.1.1'
}

repositories {
  mavenCentral()
  mavenLocal()
}

configurations {
  // Defines only those dependencies that we want to include in the assembly/shadow jar that will be used by spark-submit.
  shadowDependencies
}

dependencies {
  implementation ("org.apache.spark:spark-sql_2.12:3.4.1") {
    // The rocksdbjni dependency weighs in at 50mb and so far does not appear necessary for our use of Spark.
    exclude module: "rocksdbjni"
  }
  implementation "org.jcommander:jcommander:1.83"

  // The connector is the shadowJar with its dependencies relocated to avoid conflicts with Spark. Thus, we don't
  // need its dependencies brought in, as they're already in the connector jar itself, just in different packages.
  implementation ("com.marklogic:marklogic-spark-connector:2.2-SNAPSHOT") {
    exclude module: "marklogic-client-api"
    exclude module: "scala-java8-compat_2.12"
  }

  // hadoop-aws depends on aws-java-sdk-bundle, which clocks in as a single 380mb jar. We only need the S3 portion of
  // the AWS SDK, so the bundle is excluded in favor of the S3 API in the SDK.
  implementation ("org.apache.hadoop:hadoop-aws:3.3.6") {
    exclude module: "aws-java-sdk-bundle"
  }
  implementation "com.amazonaws:aws-java-sdk-s3:1.12.367"

  implementation "org.apache.hadoop:hadoop-client:3.3.6"

  // Spark doesn't include Avro support by default, so need to bring this in.
  implementation "org.apache.spark:spark-avro_2.12:3.4.1"

  testImplementation "com.marklogic:marklogic-junit5:1.4.0"
  // Used for tests involving JDBC. Spring JDBC greatly simplifies executing SQL queries.
  testImplementation "org.springframework:spring-jdbc:5.3.31"
  testImplementation "org.postgresql:postgresql:42.6.0"

  shadowDependencies "org.jcommander:jcommander:1.83"
  shadowDependencies "com.marklogic:marklogic-spark-connector:2.2-SNAPSHOT"
}

distributions {
  main {
    distributionBaseName = "nt"
  }
}

application {
  mainClass = "com.marklogic.newtool.Main"
  // Removes warnings due to Spark performing "illegal reflective access".
  applicationDefaultJvmArgs = ['--add-opens', 'java.base/java.nio=ALL-UNNAMED', '--add-opens', 'java.base/java.net=ALL-UNNAMED',
                               '--add-opens', 'java.base/java.lang=ALL-UNNAMED', '--add-opens', 'java.base/java.util=ALL-UNNAMED',
                               '--add-opens', 'java.base/java.util.concurrent=ALL-UNNAMED']
}

// Modifies the application's start script to use our modified one that adds jars in the "./ext" folder to the classpath.
startScripts {
  unixStartScriptGenerator.template = resources.text.fromFile('scripts/start-script.txt')
  applicationName = "nt"
}

tasks.register("deleteTool", Delete) {
  delete "../nt"
}
tasks.register("buildTool", Copy) {
  from layout.buildDirectory.dir("install/nt")
  into "../nt"
}
buildTool.dependsOn installDist, deleteTool

tasks.register("buildToolForGettingStarted", Copy) {
  description = "For testing NT with the getting-started example project."
  from layout.buildDirectory.dir("install")
  into "../examples/getting-started"
}
buildToolForGettingStarted.dependsOn installDist

test {
  finalizedBy jacocoTestReport
}

jacocoTestReport {
  dependsOn test
  reports {
    xml.required = true
  }
}

sonar {
  properties {
    property "sonar.projectKey", "spark-etl"
    property "sonar.host.url", "http://localhost:9000"
  }
}

// See https://imperceptiblethoughts.com/shadow/configuration/dependencies/#embedding-jar-files-inside-your-shadow-jar .
shadowJar {
  configurations = [project.configurations.shadowDependencies]
}
